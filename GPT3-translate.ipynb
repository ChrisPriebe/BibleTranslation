{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to fine-tune GPT3 to translate between languages\n",
    "The first language will be our made up language (see notes on get_bible as to why we think GPT is cheating)\n",
    "The thesis is that fine-tuning will cause GPT3 to learn the fake language as a new language by assigning the embeddings of the\n",
    "new words essentially to the same dimensional space as the english.  Should be trivial to translate it back as it is a word \n",
    "for word translation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.config import get_config\n",
    "import pandas as pd\n",
    "\n",
    "bible = pd.read_csv('data/bible.csv')\n",
    "\n",
    "# Assuming the gospels have a lot of overlap include the synoptic gospels plus John to train\n",
    "# then predict Mark (which should be easy as Matthew and Luke may have copied from him)\n",
    "train = bible[bible['book'].isin(['MAT','LUK','JHN'])]\n",
    "validate = bible[bible['book'].isin(['MRK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'prompt': train['engBBE'], 'completion': train['birrig']})\n",
    "df2['completion'] = df2['completion'].apply(lambda x: \" \" + x + '\\n###')\n",
    "df2['prompt'] = df2['prompt'].apply(lambda x: x + \"\\n\\n###\\n\\n\")\n",
    "df2.to_json('data/train.jsonl', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set environment variable in ipython notebook\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = get_config('openai')['api_key']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 3101 prompt-completion pairs\n",
      "- There are 13 duplicated prompt-completion sets. These are rows: [403, 593, 787, 886, 1364, 1395, 1399, 1670, 1675, 1864, 2036, 2129, 2391]\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix `\\n###`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 13 duplicate rows [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `data/train_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"data/train_prepared.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.04 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!python3 /Users/chrispriebe/Library/Python/3.8/lib/python/site-packages/openai/_openai_scripts.py tools fine_tunes.prepare_data -f data/train.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially duplicated files with name 'train_prepared.jsonl', purpose 'fine-tune' and size 871208 bytes\n",
      "file-Kz9OeIePo1hXszuPaZ12yBeU\n",
      "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 /Users/chrispriebe/Library/Python/3.8/lib/python/site-packages/openai/_openai_scripts.py api fine_tunes.create -t \"data/train_prepared.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-28 15:49:45] Created fine-tune: ft-MPF2xw4JKKURr7gU4EsxRERI\n",
      "[2023-03-28 15:52:43] Fine-tune costs $3.49\n",
      "[2023-03-28 15:52:44] Fine-tune enqueued. Queue number: 0\n",
      "[2023-03-28 15:52:46] Fine-tune started\n",
      "[2023-03-28 15:59:37] Completed epoch 1/4\n",
      "[2023-03-28 16:05:24] Completed epoch 2/4\n",
      "[2023-03-28 16:11:12] Completed epoch 3/4\n",
      "[2023-03-28 16:16:56] Completed epoch 4/4\n",
      "[2023-03-28 16:17:19] Uploaded model: curie:ft-personal-2023-03-28-23-17-19\n",
      "[2023-03-28 16:17:20] Uploaded result file: file-pFzh535nCK6OpPnjWBM65LxZ\n",
      "[2023-03-28 16:17:20] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m curie:ft-personal-2023-03-28-23-17-19 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!python3 /Users/chrispriebe/Library/Python/3.8/lib/python/site-packages/openai/_openai_scripts.py api fine_tunes.follow -i ft-MPF2xw4JKKURr7gU4EsxRERI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from lib.cipher import substitution_cipher\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def translate(text):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"curie:ft-personal-2023-03-28-23-17-19\",\n",
    "        prompt=text + \"\\n\\n###\\n\\n\",\n",
    "        temperature=0.2,\n",
    "        max_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=[\"\\n###\"]\n",
    "    )\n",
    "    translation = response.get('choices',[{}])[0].get('text').strip()\n",
    "    decoded_translation = substitution_cipher(translation, encode=False).strip()\n",
    "    bleu_score = sentence_bleu([text.split()], decoded_translation.split())\n",
    "    \n",
    "    return (translation, decoded_translation, bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Suv Guw zu puwpi ni lxel xi givi ni rih pofxor or xoz corgwun',\n",
       " 'For God so lodle me that he gere me new libhin in his kingdom',\n",
       " 6.965077358261036e-78)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"For God so loved me that he gave me new life in his kingdom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Suv Guw zu puawiw lxi huvpw lxel xi gowi xoz ulxor Zur, zu lxel jiusi hxokx orz wozir or xon nej rul woi, fal iqevopip pozi.',\n",
       " 'For God so louded the world that he gide his othin Son, so that yeofe which ins disen in him may not die, but eparilel lise.',\n",
       " 0.270465701330031)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"For God so loved the world that he gave his only Son, so that everyone who believes in him may not die but have eternal life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xi zi said lxil lxivi fi pjlur erw lxivi hez pjlur',\n",
       " 'he se fuez thet there be lyton and there was lyton',\n",
       " 4.484824319939061e-78)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"he said let there be light and there was light\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fungu fungu O puavi jua, guir lu Mivaz holx e xupi or nj zuri',\n",
       " 'Bomgo bomgo I loure you, goen to Verus with a hole in my sone',\n",
       " 0.29899503549981366)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try some unknown words\n",
    "translate(\"Bongo bongo I love you, gone to Venus with a hole in my shoe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lxi Ropi Qoli! Qvofi ekuh-pej!', 'The Nile Pite! Pribe acow-lay!', 0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate (\"Ship Pit! Pirate ahoy-lay!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fiul e fvulxiv ur e nuvlxorg',\n",
       " 'Beot a brother on a morthing',\n",
       " 0.5081327481546147)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Boat a brother on a mountain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fi ciadr erw qpej holx vokz!',\n",
       " 'Be keuzn and play with rics!',\n",
       " 6.206021746903507e-78)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Be kind and play with rocks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ZUZ! Zqoli uzbushouvl!! Puld rintj qvuhlov us qvirz!',\n",
       " 'SOS! Spite osxofwiort!! Lotz nemqy prowtir of prens!',\n",
       " 1.2882297539194154e-231)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"SOS! Ship overboard!! Lost ninty percent of people!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
